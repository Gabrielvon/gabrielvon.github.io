---
layout: post
title:  "实时更新统计值的原理与Python实现"
subtitle: "Online Calculation Illustration and Python Implementation"
date:   2018-05-27
background: ''
---

最近由于研发需求，自己推导整理了几种常见的实时更新统计的方法，并用写成python可用的函数。总的来说，只要能计算并记录每个状态的sum(总和), sum square(平方和)和count(计数)，我们就可以实时无误差地更新count, average, standard deviation, skew, kurtosis, pearson correlation等。如果涉及排序，就没办法了。虽然无误差地不用到过去信息进行全局排序是不可能的，但是有很多相关的论文提出了各种各样的方法对排序进行估计。有兴趣的同学，可以文章最后看参考文献。

本文介绍几种简单的实时更新的统计值原理。

<ul>
    <li>平均值</li>
    <li>标准差</li>
    <li>最大最小值标准化的关键统计值</li>
    <li>z-score的关键统计值</li>
</ul>




其实都挺简单，初中生数学知识就可以推导出来，只是他们没有这样的应用场景，所以也不会做到这样的题目。python实现也很简单。

假设我们有1000个样本，记为$X$, 这1000个样本不是一次给出，而是每次更新10个样本，我们每个状态也只知道这10个的信息，过去的信息已经丢失。

我们把每次更新为描述为，第b组样本里，共有m个样本，需要可以每次记录以下值。


   My text with **markdown** syntax
|Symbol|当前状态|全局最新
|---|---|---|
|平方和|$sumsq(x_b) = \sum_{j=b-m}^{b}{x_j^2}$|$sumsq(x_t) = \sum_{i=1}^{b}{sumsq(x_b)}$|
|总和|$sum(x_b) = \sum_{j=b-m}^{b}{x_j}$|$sum(x_t) = \sum_{i=1}^{b}{sum(x_b)}$|
|样本个数|$cnt(x_b) = count(x_b)$|$cnt(x_t) = \sum_{i=1}^{b}cnt(x_b)$|

<br>
 $ \bar{X_t} = \frac{sum(x_t)}{cnt(x_t)} $
 $ \sigma_t^2 = \frac{sumsq(x_t)}{cnt(x_t)} - (\frac{sum(x_t)}{cnt(x_t)})^2$


<br>
<h4> 最大最小值标准化（MinMaxScale）</h4>
如果需要记录原始数据标准化后的基本统计值，那么我们还需要对应的记录这些当前状态的最小值和最大值，进而得到全局最新的最大值和最小值。

|Symbol|当前状态|全局最新
|---|---|---|
|最小值|$mn(x_b) = min(x_b)$|$mn(x_t) = min(mn_b)$|
|最大值|$mx(x_b) = max(x_b)$|$mx(x_t) = max(mx_b)$|
 $ sumsq(z_t) = \frac{sumsq(x_b) - 2*min(x_t) + cnt(x_b)*mn(x_t)^2 }{(mx(x_t)-mn(x_t))^2}$

$sum(z_t) = \frac{sum(x_b) - cnt(x_t)*mn(x_t)}{mx(x_t)-mn(x_t)}$

<br>
<h4> Z-score </h4>
<body>需要用到最新的平均值和标准差</body>

$sumsq(z_t) = \frac{sumsq(x_b) - 2*sum(x_b)*\bar{X_t} + cnt(x_b) * \bar{X_t}^2}{\sigma^2}$
$sum(z_t) = \frac{sum(x_b) - cnt(x_b) * \bar{X_t}}{\sigma}$




#### Python实现

```python
def update_std(sumsq_x, sum_x, cnt):
    """online update standard deviation

    Args:
        sumsq_x (float): cummulative sum squre of x
        sum_x (float): cummulative sum of x
        cnt (float): cummulativef number of x, i.e. count

    Returns:
        float: global standard deviation
    """
    var = (sumsq_x - sum_x**2 / cnt) / cnt
    return np.sqrt(var)

def update_maxminscale(stats_on_target, lastest_minmax):
    """
    online maxminscale normalization

    Args:
        stats_on_target (TYPE): recorded stats in the past which is going to be updated. i.e. [sum of square, sum, count] of last
        lastest_minmax (TYPE): current status i.e. current [min, max]

    Returns:
        tuple: sumsq, sum and count
    """
    target_xss, target_xs, target_xct = stats_on_target
    xmn, xmx = lastest_minmax

    zss = (target_xss - 2 * xmn * target_xs + target_xct * xmn**2) / (xmx - xmn)**2
    zs = (target_xs - target_xct * xmn) / (xmx - xmn)
    zct = target_xct

    return zss, zs, zct


def update_zscore(stats_on_target, lastest_mustd):
    """online zscore computation

    Args:
        stats_on_target (TYPE): recorded stats in the past which is going to be updated. i.e. [sum of square, sum, count] of last
        lastest_mustd (TYPE): current status i.e. current [mean, std]

    Returns:
        tuple: sumsq, sum and count
    """
    target_xss, target_xs, target_xct = stats_on_target
    xmu, xstd = lastest_mustd

    zss = (target_xss - 2 * target_xs * xmu + target_xct * xmu ** 2) / xstd ** 2
    zs = (target_xs - target_xct * xmu) / xstd
    zct = target_xct

    return zss, zs, zct
```

References:
1. [An O(n) Sorting Algorithm: Machine Learning Sorting)](https://www.groundai.com/project/an-on-sorting-algorithm-machine-learning-sorting/)
2. [Sorting and Selection on Dynamic Data](https://www.sciencedirect.com/science/article/pii/S0304397510005475)
3. [Algorithms for calculating variance](https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance)